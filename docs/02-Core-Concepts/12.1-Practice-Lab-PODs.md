### 12.1.1 Create Pod (`Imperative` & `Declarative`)

###### Imperative Method
Imperative method is a quick and direct way to create a Pod using the `kubectl` command.
example creates a Pod named `nginx-pod` using the `nginx` container image with `port` exposed
```bash
kubectl run nginx-pod --image=nginx --port=80
```
kubectl run is only for Pods and basic Deployments ‚Äî useful for quick tests.

###### Declarative Method
Declarative Method is recommended for reusable, version-controlled configuration (common in real-world clusters)
```yaml title="pod-definition.yaml" linenums="1"
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  labels:
    app: nginx
spec:
  containers:
  - name: nginx-container
    image: nginx
    ports:
    - containerPort: 80
```

```bash
kubectl apply -f nginx-pod.yaml
```

Verify the Pod:
```bash
kubectl get pod nginx-pod
kubectl describe pod nginx-pod
```

> [!TIP]
>    - Use `--dry-run=client -o yaml` to generate YAML from imperative commands:
>        ```bash
>        kubectl run redis-pod --image=redis --dry-run=client -o yaml > redis-pod.yaml
>        ```
>    - Remember to use `kubectl apply -f <file>` for declarative management
>    - Use labels for grouping Pods for Services/Deployments.
>    - Always verify creation with `kubectl get pod` or `kubectl describe`.

---

### 12.1.2 Run Pod in Specific Namespace

###### Imperative Method
Use the `-n` or `--namespace` flag to specify the namespace.
If the namespace doesn't exist, create it:
```bash
kubectl create namespace dev
```

Create a Pod in a namespace named `dev`:
```bash
kubectl run nginx-pod --image=nginx -n dev
```
###### Declarative Method
Add the `namespace` field in the metadata section of your YAML file.

Create a sample nginx pod:
```yaml title="nginx-pod.yaml" linenums="1" hl_lines="5"
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
  namespace: dev
spec:
  containers:
  - name: nginx-container
    image: nginx
```

```bash
kubectl apply -f nginx-pod.yaml
```

Verify the Pod in a specific namespace:
```bash
kubectl get pods -n dev
```

> [!TIP]
>    You can combine `kubectl run ... --dry-run=client -o yaml` with namespace flags to generate a proper YAML file fast:
>        ```bash
>        kubectl run test-pod --image=busybox -n testing --dry-run=client -o yaml > test-pod.yaml
>        ```

---

### 12.1.3 Define Restart Policies (Always, OnFailure, Never)
In Kubernetes, restart policies define how a Pod‚Äôs containers should be restarted when they exit.
Restart policies apply only to Pods (The `restartPolicy` applies only to containers within a single Pod.), not to higher-level controllers like Deployments (which manage Pods differently).

There are three restart policies:

| Policy      | Behavior                                                             | Common Use Case                       |
| ----------- | -------------------------------------------------------------------- | ------------------------------------- |
| `Always`    | Restart the container if it exits for any reason (default for Pods). | Long-running apps (web servers, APIs) |
| `OnFailure` | Restart only if the container exits with a non-zero status code.     | Batch jobs that may fail on errors    |
| `Never`     | Never restart the container after it exits.                          | Debug/troubleshooting, one-off tasks  |

###### Restart Policy: `Always` (default) is the default and is best for applications that are expected to run continuously, like a web server.
```yaml title="pod-definition.yaml" linenums="1" hl_lines="6"
apiVersion: v1
kind: Pod
metadata:
  name: pod-always
spec:
  restartPolicy: Always
  containers:
  - name: nginx
    image: nginx
```

###### Restart Policy: `OnFailure` is useful for jobs that are designed to retry on failure but should stop if they complete successfully (exit code 0).
```yaml title="pod-definition.yaml" linenums="1" hl_lines="6"
apiVersion: v1
kind: Pod
metadata:
  name: pod-onfailure
spec:
  restartPolicy: OnFailure
  containers:
  - name: busybox
    image: busybox
    command: ['sh', '-c', 'exit 1']
```

###### Restart Policy: `Never` is used when you explicitly want the container to stop permanently after its task is complete, regardless of success or failure.
```yaml title="pod-definition.yaml" linenums="1" hl_lines="6"
apiVersion: v1
kind: Pod
metadata:
  name: pod-never
spec:
  restartPolicy: Never
  containers:
  - name: busybox
    image: busybox
    command: ['sh', '-c', 'echo Hello Kubernetes']
```

> [!TIP]
>    * Restart policies only apply to Pods created directly via `kubectl run` or YAML manifests.
>    * For Deployments, ReplicaSets, and DaemonSets, the restart policy is always `Always` (not configurable).
>    * For `Jobs` and `CronJobs`, you generally use `OnFailure` or `Never`.

---

### 12.1.4 View Pod Logs (`logs`, `-f`, `--previous`, `--since`, `--since-time`)
Viewing Pod logs is an essential operational. Kubernetes provides several useful options for inspecting logs from running or crashed containers.

```bash
# View logs of a Pod's container
kubectl logs nginx-pod

# View Logs in Real-Time Use -f (follow) to stream logs as they are generated (like tail -f)
kubectl logs -f nginx-pod

# If a container has crashed and restarted, use --previous to see its logs:
kubectl logs nginx-pod --previous

# If a Pod has multiple containers, you must specify the container name:
kubectl logs multi-container-pod -c app-container

# Combine filtering and flags
kubectl logs -f nginx-pod | grep "ERROR"

# If a Pod is in CrashLoopBackOff, always check:
kubectl describe pod nginx-pod
```

The `--since` flag lets you view logs generated only within a specific time period, such as the last 5 minutes, 1 hour, etc
```bash
# follow logs from last 5 mins
kubectl logs -f nginx-pod --since=5m

# more precision
kubectl logs nginx-pod --since-time="2024-11-06T15:04:05Z"
```

> [!TIP]
>    Combine Flags for Powerful Monitoring
>    ```bash 
>    kubectl logs -f <pod-name> --since=30m          # <-- Follow logs from last 30 mins
>    kubectl logs <pod-name> --previous --since=1h   # <-- Previous crash logs from last 1 hour
>    kubectl logs -f <pod-name> -c <container-name>  # <-- Follow specific container logs
>    ```

---

### 12.1.5 Execute Commands Inside Pod (direct & via Bastion)

**Basic Command Execution Inside a Pod (Directly)**

Run a single command
```bash
kubectl exec nginx-pod -- ls /usr/share/nginx/html
```

Specify a container (if multiple)
```bash
kubectl exec -it multi-container-pod -c sidecar -- /bin/sh
```

**Execute Commands via Bastion Host (Jump Box)**

1Ô∏è‚É£ SSH into the Bastion Host
```bash
ssh user@<bastion-server-ip>
```

2Ô∏è‚É£ Verify kubeconfig
```bash
kubectl get nodes
```

* If this works, your context is set correctly.
* If not, check the path:
  ```bash
  export KUBECONFIG=/etc/kubernetes/admin.conf
  ```

3Ô∏è‚É£ Now you can run `exec` commands normally on bastion server:
```bash
kubectl exec -it app-pod -- /bin/bash
```


  >  To run command in a specific namespace `kubectl exec -n my-namespace -it my-pod -- /bin/sh`
    
---

### 12.1.6 Environment Variables (env, envFrom, ConfigMap, Secret)

üß© **`env` Define Environment Variables Directly in a Pod**

```yaml title="simple-env-pod.yaml" linenums="1" hl_lines="10-14"
apiVersion: v1
kind: Pod
metadata:
  name: env-demo
spec:
  containers:
    - name: app
      image: busybox
      command: ['sh', '-c', 'env; sleep 3600']
      env:
        - name: MY_VAR
          value: "hello"
        - name: APP_MODE
          value: "production"
```

```sh
kubectl apply -f env-demo.yaml
```

check `env` vars:
```sh
kubectl exec -it env-demo -- env
```

üß© **Use `envFrom` to Import All Variables from a `ConfigMap`**

1Ô∏è‚É£ Create a ConfigMap
```bash
kubectl create configmap app-config \
  --from-literal=APP_COLOR=blue \
  --from-literal=APP_MODE=prod
```

2Ô∏è‚É£ Use in Pod
```yaml title="envfrom-configmap-pod.yaml" linenums="1" hl_lines="10-12"
apiVersion: v1
kind: Pod
metadata:
  name: cm-demo
spec:
  containers:
    - name: app
      image: busybox
      command: ['sh', '-c', 'env; sleep 3600']
      envFrom:
        - configMapRef:
            name: app-config
```
3Ô∏è‚É£ Verify
```bash
kubectl exec -it cm-demo -- env | grep APP_
```

üß© **Use `envFrom` to Import All Variables from a `Secret`**

1Ô∏è‚É£ Create Secret
```bash
kubectl create secret generic app-secret \
  --from-literal=DB_USER=admin \
  --from-literal=DB_PASS=12345
```


2Ô∏è‚É£ Use in Pod
```yaml title="envfrom-secret-pod.yaml" linenums="1" hl_lines="10-12"
apiVersion: v1
kind: Pod
metadata:
  name: secret-demo
spec:
  containers:
    - name: app
      image: busybox
      command: ['sh', '-c', 'env; sleep 3600']
      envFrom:
        - secretRef:
            name: app-secret
```
3Ô∏è‚É£ Verify
```bash
kubectl exec -it secret-demo -- env | grep DB_
```

> [!TIP]
>    Values from secrets appear decoded inside containers ‚Äî base64 decoding is only for manifest inspection.

üß© **Use `env` to Reference Individual Keys from `ConfigMap` or `Secret`**

_From `ConfigMap`_
```yaml title="configmap-single-env-pod.yaml" linenums="1" hl_lines="10-15"
apiVersion: v1
kind: Pod
metadata:
  name: configmap-single-env
spec:
  containers:
    - name: app
      image: busybox
      command: ['sh', '-c', 'echo $APP_COLOR; sleep 3600']
      env:
        - name: APP_COLOR
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: APP_COLOR
```

_From `Secret`_
```yaml title="secret-single-env-pod.yaml" linenums="1" hl_lines="10-15"
apiVersion: v1
kind: Pod
metadata:
  name: secret-single-env
spec:
  containers:
    - name: app
      image: busybox
      command: ['sh', '-c', 'echo $DB_USER; sleep 3600']
      env:
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: DB_USER
```

_Combine All_

```yaml title="combine-all-pod.yaml" linenums="1" hl_lines="10-27"
apiVersion: v1
kind: Pod
metadata:
  name: full-env-demo
spec:
  containers:
    - name: app
      image: busybox
      command: ['sh', '-c', 'env; sleep 3600']
      env:
        - name: STATIC_VAR
          value: "manual"
        - name: COLOR
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: APP_COLOR
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: app-secret
              key: DB_USER
      envFrom:
        - configMapRef:
            name: app-config
        - secretRef:
            name: app-secret
```

> [!NOTE]
>    Inspect Environment Variables in a Running Pod
>    ```bash 
>
>    # Quick check
>    kubectl exec -it <pod> -- env
>
>    # Filter specific variables
>    kubectl exec -it <pod> -- env | grep APP_
>
>    # Describe Pod (shows source refs) Look under Environment: section ‚Äî shows where each var came from (ConfigMap/Secret)
>    kubectl describe pod <pod-name>
>    ```
    
| Source                 | Method    | YAML Key                    | Example                  |
| ---------------------- | --------- | --------------------------- | ------------------------ |
| Literal                | `env`     | `value:`                    | `name: MODE, value: dev` |
| ConfigMap (single key) | `env`     | `valueFrom.configMapKeyRef` | `key: APP_COLOR`         |
| ConfigMap (all keys)   | `envFrom` | `configMapRef`              | `name: app-config`       |
| Secret (single key)    | `env`     | `valueFrom.secretKeyRef`    | `key: DB_USER`           |
| Secret (all keys)      | `envFrom` | `secretRef`                 | `name: app-secret`       |

---

### 12.1.7 Copy Files (Host ‚Üî Pod)

Copying files between your local host and a Pod is a common task using syntax

üß© **Copy a file from Host to Pod**

```bash
# syntax
kubectl cp /path/on/host <namespace>/<pod-name>:/path/in/pod

# copy a index.html file from host to pod
kubectl cp ./index.html my-namespace/nginx-pod:/usr/share/nginx/html/index.html

# If the Pod is in the default namespace, you can omit it
kubectl cp ./index.html nginx-pod:/usr/share/nginx/html/
```

üß© **Copy a file from Pod to Host**

```bash
# syntax
kubectl cp <namespace>/<pod-name>:/path/in/pod /path/on/host

# copy a file from pod to host
kubectl cp my-namespace/nginx-pod:/etc/nginx/nginx.conf ./nginx.conf
```

If the Pod has multiple containers, Specify the container name using `-c`:
```bash
# syntax
kubectl cp <namespace>/<pod-name>:/path/in/pod /path/on/host -c <container-name>

# copy a file from 'sidecar' container to host,
kubectl cp default/multi-container-pod:/app/logs ./logs -c sidecar
```

> [!INFO]
>    If `kubectl cp` fails (e.g. `tar` not found in container), Some minimal container images don‚Äôt have the `tar` binary, which `kubectl cp` uses internally.
>
>    workaround:
>    ```bash
>    # Copy using exec and redirection
>    kubectl exec <pod> -- cat /path/in/pod/file.txt > ./file.txt
>
>    # Or to copy from host to pod:
>    cat ./file.txt | kubectl exec -i <pod> -- sh -c 'cat > /path/in/pod/file.txt'
>    ```

---

### 12.1.8 Multi-container Pod (Sidecar)

In Kubernetes, a Pod is the smallest deployable unit ‚Äî it can contain one or more containers that share the same:

 - Network namespace (same IP address, same ports)
 - Storage volumes
 - Lifecycle (they start, stop, and are scheduled together)

When a Pod has multiple containers, those containers can work together closely.
A Sidecar is one of the most common patterns for using multi-container Pods.

**Sidecar Pattern**

A Sidecar container is a secondary container that runs alongside the main application container to enhance or support its functionality ‚Äî without changing the main application code. Think of a sidecar motorcycle ‚Äî the main bike (primary app) does the driving, and the sidecar helps carry gear or perform extra functions.

**Examples of Sidecar Usage**

| Use Case          | Main Container                     | Sidecar Container                                     |
| ----------------- | ---------------------------------- | ----------------------------------------------------- |
| **Logging**       | Application writing logs           | Fluentd or Logstash sending logs to ELK               |
| **Proxy**         | Web app                            | Envoy or Istio sidecar proxy for service mesh         |
| **Data Sync**     | App writing files to local storage | Sync container pushing data to cloud                  |
| **Config Reload** | App reading config file            | Sidecar watching for config changes and updating file |

```yaml title="multi-container-pod.yaml" linenums="1" hl_lines="7-11 12-17" 
apiVersion: v1
kind: Pod
metadata:
  name: sidecar-demo
spec:
  containers:
  - name: main-app      # <-- main-app container
    image: nginx
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
  - name: log-shipper   # <-- sidecar container
    image: busybox
    command: ['sh', '-c', 'tail -n+1 -F /var/log/nginx/access.log']
    volumeMounts:
    - name: shared-logs
      mountPath: /var/log/nginx
  volumes:
  - name: shared-logs
    emptyDir: {}
```

Here:

 - Both containers share `/var/log/nginx` using an `emptyDir` volume.
 - The main container (nginx) writes logs there.
 - The sidecar container (busybox) tails those logs or could send them somewhere.

---

### 12.1.9 Init Containers

An **init Container** is a special type of container that runs before the main application containers in a Pod start.

**Key Points:**

 - Runs **sequentially** (one after another, in the order they‚Äôre defined).
 - Each must **complete successfully** before the next starts.
 - Used to **set up prerequisites** or **prepare the environment** for the main containers.
 - After all init containers finish, they‚Äôre **terminated**, and **app containers** start.

**Common Use Cases for Init Containers**

| Use Case                | Description                                                       |
| ----------------------- | ----------------------------------------------------------------- |
| **Wait for a service**  | e.g., wait for a database to be reachable before starting the app |
| **Configuration setup** | e.g., fetch configuration files from a remote source              |
| **Data initialization** | e.g., load seed data into a volume                                |
| **Permissions fix**     | e.g., adjust file or directory permissions before app starts      |

```yaml title="init-container-pod.yaml" linenums="1" hl_lines="6-9 11-15" 
apiVersion: v1
kind: Pod
metadata:
  name: init-demo
spec:
  initContainers:
  - name: init-check-db
    image: busybox
    command: ['sh', '-c', 'until nslookup mydb-service; do echo waiting for db; sleep 2; done;']

  containers:
  - name: app
    image: nginx
    ports:
    - containerPort: 80
```
Here:

 - The `init` container `init-check-db` runs first.
 - It loops until the DNS name `mydb-service` resolves (simulating waiting for a DB).
 - Once that‚Äôs done, it exits successfully.
 - The main container **(nginx)** starts running.

---

### 12.1.10 Ephemeral Containers _(for debugging)_

**Ephemeral Containers** are **temporary containers** you can **add to a running Pod for debugging purposes** ‚Äî _without restarting or changing the original Pod spec._

**They‚Äôre useful because:**

 - Sometimes you can‚Äôt kubectl exec into a container (for example, if it has no shell, or is crash-looping).
 - You can attach a debug container to inspect the same namespaces (network, storage, etc.) as the running Pod.

Introduced in **Kubernetes 1.23+**, and now stable in **Kubernetes 1.25+**.

**How They Work**
```bash
kubectl debug -it <pod-name> --image=<debug-image> --target=<container-name>
```

**The ephemeral container:**

 - Runs in the same Pod namespace.
 - Does not appear in `.spec.containers` (it‚Äôs listed under `.spec.ephemeralContainers`).
 - Is not restarted if it exits.
 - Exists only until the Pod terminates.

**Example Scenario**

A Pod named `webapp` is running in the `default` namespace. 

_You need to:_

 * Add a **debug container** named `debugger` using image `busybox` to inspect the running container in that Pod.
 * Connect interactively to it (`sh` shell).
 * Verify network connectivity by pinging **google.com**.
 * Exit once done.

1Ô∏è‚É£ Check existing pods
```bash
kubectl get pods

# Sample Output
NAME      READY   STATUS    RESTARTS   AGE
webapp    1/1     Running   0          5m
```

2Ô∏è‚É£ Add an ephemeral container
```bash
kubectl debug -it webapp --image=busybox --target=webapp --name=debugger
```

_Explanation:_

 - `--image=busybox`: the debugging image
 - `--target=webapp`: targets the main container‚Äôs namespaces
 - `--name=debugger`: gives a name to your ephemeral container
 - `-it`: interactive terminal

3Ô∏è‚É£ Inside the ephemeral container

Run:

```bash
sh
ping -c 3 google.com

# Sample Output
PING google.com (142.250.190.46): 56 data bytes
64 bytes from 142.250.190.46: seq=0 ttl=117 time=15.2 ms
...
```

4Ô∏è‚É£ Exit the container

```bash
exit
```

5Ô∏è‚É£ Verify ephemeral container attached

You can inspect the Pod definition:

```bash
kubectl get pod webapp -o yaml | grep -A5 ephemeralContainers
```

```yaml
# Example Output
ephemeralContainers:
- name: debugger
  image: busybox
  command:
  - sh
  targetContainerName: webapp
```

> [!NOTE]
>    Ephemeral containers can only be added via `kubectl debug` or **API**, but for understanding, here‚Äôs what it looks like inside the Pod manifest:
>    ```yaml
>    spec:
>      ephemeralContainers:
>      - name: debugger
>        image: busybox
>        command:
>        - sh
>        stdin: true
>        tty: true
>        targetContainerName: webapp
>    ```
>    **Cleanup:** Ephemeral containers disappear when the Pod is deleted _‚Äî no cleanup needed_.


---

### 12.1.11 Pod PriorityClass

**Pod priority** decides which Pods should be scheduled first and which Pods should stay alive when the cluster is under pressure.
**Higher priority = more important = survives eviction longer.**
Used heavily in production to protect critical workloads.

_Create a PriorityClass -> assign to to Pod/Deployment -> verify preemption -> find prioriy of pod_

üß© **High PriorityClass**

1Ô∏è‚É£ Create a PriorityClass _(Imperative style doesn‚Äôt exist, so YAML only)_

```yaml title="priorityclass-high.yaml" linenums="1"
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority
value: 100000
globalDefault: false
description: "High priority for critical workloads"
```
```bash
kubectl apply -f priorityclass-high.yaml
```

2Ô∏è‚É£ Create a Pod using this PriorityClass

```yaml title="pod-high.yaml" linenums="1"
apiVersion: v1
kind: Pod
metadata:
  name: high-priority-pod
spec:
  priorityClassName: high-priority
  containers:
    - name: nginx
      image: nginx
```
```bash
kubectl apply -f pod-high.yaml
```

3Ô∏è‚É£ Verify Priority of the Pod

```bash
kubectl get pod high-priority-pod -o jsonpath='{.spec.priority}'
```
You should see **100000**.

Also
```bash
kubectl describe pod high-priority-pod | grep Priority
```

üß© **Low PriorityClass**

4Ô∏è‚É£ Create a Low PriorityClass (to simulate eviction behavior)

```yaml title="priorityclass-low.yaml" linenums="1"
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: low-priority
value: 10
globalDefault: false
description: "Low priority for non-critical workloads"
```

Low Priority Pod

```yaml title="low-priority-pod.yaml" linenums="1"
apiVersion: v1
kind: Pod
metadata:
  name: low-priority-pod
spec:
  priorityClassName: low-priority
  containers:
    - name: busy
      image: busybox
      command: ["sh", "-c", "sleep 3600"]
```

Verify Priority of Pods

```bash
kubectl get pod low-priority-pod -o jsonpath='{.spec.priority}'
```

5Ô∏è‚É£ Test Eviction Logic (Optional but great practice)

If the node becomes full (e.g., limit CPU/Memory):

 * Higher priority pods always get scheduled first
 * Lower priority pods get preempted (deleted)

To simulate low resource:
```bash
kubectl set resources deployment <deploy> --limits=cpu=50m --requests=50m
```
Or create many pods on a single node.

You‚Äôll see messages in events:
```bash
kubectl describe pod low-priority-pod
```

Look for:
```csharp
Preempted by pod high-priority-pod
```

> [!NOTE]
>    * PriorityClass is NOT namespaced It‚Äôs cluster-wide.
>    * Pod preemption happens only when:
>        - There is resource pressure
>        - A higher-priority pod cannot schedule
>    * Priority value can be ANY integer
>        - Higher number = higher priority.
    
> [!TIP]
>    If you want to force an eviction scenario:
>
>    Run a memory hog:
>    ```bash
>    kubectl run hog --image=busybox --restart=Never -- sh -c "tail /dev/zero"
>    ```
>    Low-priority Pods are usually evicted first.
>
>    Check eviction events:
>    ```bash
>    kubectl get events --sort-by=.metadata.creationTimestamp
>    ```

> [!NOTE]
>    Most Used Commands for CKA
>    ```bash
>    kubectl get priorityclass
>    kubectl describe priorityclass high-priority
>    kubectl get pod -o jsonpath='{.spec.priority}'
>    ```

### 12.1.12 Manual Static Scheduling (via `nodeName`)

Manual static scheduling is when **you schedule a Pod to a specific node yourself**, instead of letting the Kubernetes scheduler decide.

You do this by adding:
```yaml
nodeName: <node-name>
```
under `.spec` in the Pod manifest.

When `nodeName` is used, **the scheduler is completely bypassed**.

Kubelet on that node directly creates the Pod ‚Äî ONLY if:

 * the node exists
 * the kubelet on that node sees the Pod definition
 * resources are available

If the `nodeName` is wrong or **unreachable** ‚Üí Pod stays in **Pending** forever.

1Ô∏è‚É£ Identify Node Names:

```bash
kubectl get nodes

# example output
node1
node2
controlplane
```

Pick any node, e.g. `node1`.

2Ô∏è‚É£ Create a Pod Manifest with `nodeName`:
```yaml title="manual-schedule-pod.yaml" linenums="1"
apiVersion: v1
kind: Pod
metadata:
  name: manual-schedule-pod
spec:
  nodeName: node1   # <-- manually assign
  containers:
  - name: nginx
    image: nginx
```

```bash
kubectl apply -f manual-schedul-pod.yaml
```

3Ô∏è‚É£ Verify the `Pod` is Running on the Correct `Node`:

```bash
kubectl get pod -o wide

# expected ouput
NAME                 NODE
manual-schedule-pod  node1
```

**What if you give the wrong `nodeName`?**

Try this:
```yaml
nodeName: wrongnode123 # <-- some wrong nodeName
```

Result:
```bash
kubectl get pod manual-schedule-pod -o wide
```

You will see:
```arduino
Pending   0/1 nodes available
```
Because no node matches.

> [!INFO]
>    When is Manual Static Scheduling used?
>
>     * **CKA exam:** Simple way to force a Pod on a node.
>     * **Learning kube-scheduler behavior:** Shows how scheduler is bypassed.
>     * **Testing node-specific workloads:** e.g., GPU nodes, storage nodes.
>     * **Emergency scheduling:** Rare in real clusters; usually use `NodeSelectors` / `Affinity` / `Taints`.


üÜö `Manual Static Scheduling` vs `NodeSelector`

| Feature                     | nodeName          | nodeSelector                      |
| --------------------------- | ----------------- | --------------------------------- |
| Schedules without scheduler | ‚úÖ                 | ‚ùå                               |
| Hard binding                | Very Hard         | Medium                            |
| If node unavailable         | Pod stuck Pending | Scheduler will try when available |
| Used in real production     | Rare              | Common                            |

---

### 12.1.13 Delete Pod (effect on Deployment)

üß© **Pod Deletion**

Get the pod name:
```bash
kubectl get pods -n namespace-name
```

Delete the pod
```bash
kubectl delete pod <pod-name> -n namespace-name
```
üß© **Delete a Pod Managed by Deployment**

**What Happens When You Delete a Pod Managed by a Deployment?** Kubernetes automatically recreates it.

**Effect of Deleting a Pod on a Deployment:**

1Ô∏è‚É£ **Automatic Pod Recreation:**

 * Kubernetes will automatically detect that the pod has been deleted and will try to recreate a new one to match the desired number of replicas specified in the Deployment.
 * A Deployment manages the desired state of your application. If you have a replicas: 3 configuration, for example, and you delete one pod, Kubernetes will create a new pod to ensure that the total number of pods is 3 again.

2Ô∏è‚É£ **Rolling Updates or Rollbacks:**

 * If you are in the middle of a rolling update, deleting a pod might cause Kubernetes to replace it with a new pod as part of the update process.
 * If there are issues with the pod deletion, the Deployment might trigger a rollback to the previous stable state to maintain consistency.

3Ô∏è‚É£ **Impact on Application Availability:**

 * If there is more than one replica and the pod is deleted, Kubernetes will try to schedule a new pod on an available node. If there are not enough resources available, the new pod might experience delays.
 * However, in the case of single-replica deployments, deleting the pod might temporarily disrupt service until the new pod is created.

4Ô∏è‚É£ **No Manual Intervention Needed:**

 * One of the primary advantages of using Deployments is that they manage the lifecycle of pods automatically. You don't need to manually intervene to keep your application running after a pod is deleted.

**Example Scenario:** Assume you have the following Deployment configuration
```yaml title="nginx-deployment.yaml" linenums="1" hl_lines="6"
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx-deployment
        image: nginx:latest
```

```bash
kubectl apply -f nginx-deployment.yaml
```

One the Pod are up and running Delete Pod in Deployment:
```bash
kubectl delete pod nginx-deployment-7c77b68cff-abcde

# sample output
nginx-deployment-7c77b68cff-abcde   Terminating
nginx-deployment-7c77b68cff-fghij   Running
nginx-deployment-7c77b68cff-klmno   Running
nginx-deployment-7c77b68cff-pqrst   ContainerCreating
```
If you delete one of the pods, Kubernetes will notice that the desired state (3 replicas) does not match the actual state (2 replicas), and it will create a new pod to maintain the desired state of 3 replicas.

> [!IMPORTANT]
>    When a `Pod` is controlled by a `Deployment`/`ReplicaSet` in Kubernetes and you delete it, Kubernetes automatically recreates the pod to maintain the desired replica count.

---


### 12.1.14 Restart Pod

**"restart pod"** typically refers to the task of restarting a Kubernetes pod, which is often done to verify your understanding of pod management, especially in troubleshooting or updating scenarios.

When you delete a pod in a Deployment or ReplicaSet, Kubernetes will automatically recreate the pod to maintain the desired state (number of replicas). This can be considered as "restarting" the pod.

> [!WARNING]
>    There is no direct `kubectl restart pod` command in Kubernetes like `docker restart container`.

---

### 12.1.15 Debug Failing Pod (`kubectl debug`)

Debug a failing pod. This can involve identifying the issue with the pod, understanding its logs, and using tools to inspect the pod or the underlying system for potential problems.

One of the key tools for debugging a failing pod in Kubernetes is the `kubectl debug` command. This allows you to create a temporary container in a pod for debugging purposes, which can be especially helpful if you need to troubleshoot issues like **container crashes, misconfigurations, or resource limits**.

**Here's how you can approach debugging a failing pod:**

1Ô∏è‚É£ **Inspect the Pod**

First, you should inspect the pod and check the basic details to understand the situation: This will give you a lot of information, including events, container status, logs, and resource usage. Look for events like `CrashLoopBackOff`, `ImagePullBackOff`, or any failed container states.

```bash
kubectl describe pod <pod-name> --namespace=<namespace>
```
2Ô∏è‚É£ **Check Pod Logs**

Next, check the logs of the container(s) in the pod to look for error messages that might indicate why the pod is failing:
```bash
kubectl logs <pod-name> --namespace=<namespace>
```

If the pod has multiple containers, you may need to specify the container name using the -c flag:
```bash
kubectl logs <pod-name> -c <container-name> --namespace=<namespace>
```

3Ô∏è‚É£ **Debugging with kubectl debug**

`kubectl debug` is a powerful command that helps you start a temporary debug container in the same pod or in a new pod. This is especially useful for inspecting the pod's environment and configuration without modifying the pod's existing setup.

* **Start a temporary container in the same pod (same namespace):**
  If you want to attach a debug container to the pod that is failing, you can use the following command:
  ```bash
  kubectl debug <pod-name> --namespace=<namespace> -it --image=busybox
  ```
  This starts a new busybox container in the same pod, and you can use the shell to check the file system, network, and other configurations. This can help you understand the pod's environment. You can also use a more specialized debugging image, like nicolaka/netshoot, which provides networking tools for debugging network-related issues.

* **Start a debug container with `--copy-to`:**
  If the pod is in a `CrashLoopBackOff` state and you want to debug it without affecting the original pod, you can copy the failing pod's configuration and then debug:
  ```bash
  kubectl debug <pod-name> --namespace=<namespace> --copy-to=<new-pod-name> -it --image=busybox
  ```
  This creates a new pod with the same configuration as the original, allowing you to make changes or debug without modifying the failing pod directly.

* **Run `kubectl debug` for a container in a pod:**
  You can also debug a specific container in a pod:
  ```bash
  kubectl debug <pod-name> -c <container-name> --namespace=<namespace> -it --image=busybox
  ```
  This allows you to start a new debug container in the same namespace and pod but specifically targets the container you want to debug.

> [!INFO]
>    Common Issues:
>
>      * `CrashLoopBackOff`: Check logs for crashes or misconfigurations.
>      * `ImagePullBackOff`: Check image name and pull secrets.
>      * `Resource Limits`: Check for memory/CPU overuse.

---

### 12.1.16 Get Pod IP

To get the Pod IP in a Kubernetes (CKA) lab environment, you can use several kubectl commands depending on how much detail you want.

üß© **Get the Pod IP**: A pod named `web-pod` is running in the `default` namespace.
```bash
kubectl get pod web-pod -o wide
```

_Describe the pod (also shows IP)_
```bash
kubectl describe web-pod
```
Alternative, to get only IP
```bash
kubectl get pod web-pod -o jsonpath='{.status.podIP}'
```

üß© **List all Pod IPs in a namespace**: In the namespace `dev`, list **all pod names and their IPs**.
```bash
kubectl get pods -n dev -o jsonpath='{range .items[*]}{.metadata.name}{" => "}{.status.podIP}{"\n"}{end}'
```

üß© **Verify that a Pod has no IP yet**: A pod named `pending-app` is stuck in **Pending**. Check whether it has been assigned an IP.
```bash
kubectl get pod pending-app -o jsonpath='{.status.podIP}'
```
If it's empty, the pod has **no IP assigned**.

üß© **Check Pod IP from inside the Pod**: Exec into pod `tools` and show its own IP from inside the container.
```bash
kubectl exec -it tools -- ip addr show eth0
```
or
```bash
kubectl exec -it tools -- hostname -i
```

üß© **Find Pod IP from a Service**: A Service named `backend-svc` selects Pods with label `app=backend`. List the IPs of Pods behind this Service.
```bash
kubectl get pods -l app=backend -o jsonpath='{range .items[*]}{.metadata.name}{" => "}{.status.podIP}{"\n"}{end}'
```
---

### 12.1.17 Get YAML of Existing Pod (kubectl get pod -o yaml)

üß©  **Lab-1 Export YAML and Recreate Pod**

A pod named `busybox-pod` is running in the `default` namespace.
Export its YAML to a file named `busybox.yaml`, then delete the pod and recreate it from the saved YAML.

```bash
# Export as YAML file
kubectl get pod busybox-pod -o yaml > busybox.yaml

# Delete the existing Pod
kubectl delete pod busybox-pod

# Creating Pod using manifest file exported
kubectl apply -f busybox.yaml
```

üß©  **Lab-2 Create New Pod From Existing Pod‚Äôs YAML**

Get the YAML of an existing pod `nginx-pod`, edit the name to `nginx-copy`, and create the new pod.

```bash
kubectl get pod nginx-pod -o yaml > nginx-pod.yaml

vi nginx-pod.yaml
# Change:
# metadata:
#   name: nginx-copy

kubectl apply -f nginx-pod.yaml
```

üß©  **Lab-3 Fix Immutable Field Error**

You change the container image, but you get an **error** saying you cannot update an **immutable** field. 
Pod specs are **immutable**. You must **delete and recreate the pod**.
```bash
kubectl edit pod web
```

```bash
kubectl get pod web -o yaml > web.yaml

kubectl delete pod web

vi web.yaml   # update container image

kubectl apply -f web.yaml
```

üß©  **Lab-4 Get a Clean YAML Without Status Fields**

Get the YAML of pod `app-pod` without **status**, **UID**, **resourceVersion**, or **managedFields** so it can be reused.

```bash
kubectl get pod app-pod -o yaml \
  | grep -v "uid:" \
  | grep -v "resourceVersion:" \
  | grep -v "managedFields:" \
  | grep -v "selfLink:" \
  | grep -v "creationTimestamp:" \
  | grep -v "status:" > clean-app.yaml
```

üß©  **Lab-5 Extract Only the Pod Spec** _(useful for `replicasets`, `deployments`)_

Extract only the .spec of a pod named db-pod.
```bash
kubectl get pod db-pod -o jsonpath='{.spec}'
```

üß©  **Lab-5 Generate YAML Template for a Pod** _(without existing pod)_

Generate a YAML skeleton for a pod called `testpod` with image `nginx`, no running pod required.
```bash
kubectl run testpod --image=nginx --dry-run=client -o yaml > testpod.yaml
```

üß©  **Lab-6 Patch an Existing Pod** _(in-line)_

Update a label on a running pod frontend without editing full YAML.
```bash
kubectl patch pod frontend -p '{"metadata":{"labels":{"tier":"frontend"}}}'
```

---

### 12.1.18 Use `kubectl explain` for field reference

`kubectl explain` is used for viewing Kubernetes API documentation directly from the command line, without needing external docs.

**General Syntax of kubectl explain**

To view the documentation for a specific resource, you use the following syntax:
```bash
kubectl explain <resource-name>.<field-name>
```

**Explaining a Pod Resource:** If you want to understand the structure of a Pod's specification and its fields, you can run:
```bash
kubectl explain pod

# Sample Output
KIND:     Pod
VERSION:  v1

DESCRIPTION:
     Pod is a collection of containers that can run on a host. A Pod models an
     application-specific "logical host" and can contain different application
     containers which are relatively tightly coupled. The containers in a Pod
     share the same network namespace, including the same IP address and port
     space, and can find each other via 'localhost'. They also share storage
     volumes, which allows data to be shared between containers in the Pod.
     A Pod's contents can be replaced by a new version, but they cannot be scaled
     independently.

FIELDS:
   apiVersion   <string>
     IP versioned API object.

   kind         <string>
     Kind is a string value representing the REST resource this object represents.

   metadata     <Object>
     Standard object's metadata.

   spec         <Object>
     Specification of the desired behavior of the pod.

   status       <Object>
     Current status of the pod.
```

**Explaining the `spec` Field in a Pod**

To explore the `spec` field of a Pod resource, which contains information about the Pod‚Äôs desired state (such as containers, volumes, etc.), you would use:

```bash
kubectl explain pod.spec
```

**Explaining the `containers` Field in a Pod Spec**

You can drill down further into the containers field, which is a list of containers within the Pod.
```bash
kubectl explain pod.spec.containers
```

**Explaining the `env` Field in a Container**

If you need to configure environment variables for containers, you can explore the env field under containers:

```bash
kubectl explain pod.spec.containers.env
```

**Explaining a `Deployment` Resource**

Now, let's look at how you might explore a Deployment resource. For example, to understand the spec of a Deployment:

```bash
kubectl explain deployment.spec
```

**Explaining the `strategy` Field in a Deployment**

You can also explain the strategy field of the Deployment resource to understand how it handles rolling updates or recreate strategies:

```bash
kubectl explain deployment.spec.strategy
```

> [!INFO]
>    `kubectl explain` helps you reference field documentation quickly. It is a powerful tool to check the structure and available fields for resources like `Pods`, `Deployments`, `Services`, and many others. You can also drill down to nested fields, making it easier to create and troubleshoot configurations.

---